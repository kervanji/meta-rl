import tkinter as tk
from tkinter import scrolledtext
import numpy as np
import matplotlib.pyplot as plt
import arabic_reshaper
from bidi.algorithm import get_display


# ==========================================
# 1. دوال العرض التوضيحي (Demo Functions)
# لرسم أمثلة بصرية للمفاهيم الأساسية
# ==========================================
def show_connectivity_demo():
    x = np.array([0.1, 0.4, 0.8, 0.3, 0.7], dtype=float)
    y = np.array([0.2, 0.8, 0.6, 0.4, 0.1], dtype=float)

    def shape(text: str) -> str:
        return get_display(arabic_reshaper.reshape(text))

    def plot_for_range(comm_range, subplot_idx, title):
        plt.subplot(1, 2, subplot_idx)
        plt.scatter(x, y, c="blue")
        for i in range(len(x)):
            for j in range(i + 1, len(x)):
                dist = np.sqrt((x[j] - x[i]) ** 2 + (y[j] - y[i]) ** 2)
                if dist <= comm_range:
                    plt.plot([x[i], x[j]], [y[i], y[j]], "g-")
        for i, xi in enumerate(x):
            label = shape(f"حساس {i+1}")
            plt.text(xi, y[i] + 0.03, label, ha="center", fontsize=9)
        plt.title(shape(title))
        plt.xlim(0, 1)
        plt.ylim(0, 1)
        plt.xlabel("")
        plt.ylabel("")

    plt.figure(figsize=(8, 3))
    plot_for_range(0.6, 1, "مدى اتصال صغير")
    plot_for_range(1.6, 2, "مدى اتصال أكبر")
    plt.suptitle(shape("تأثير مدى الاتصال (comm_range) على الروابط بين الحساسات"), fontsize=11)
    plt.tight_layout()
    plt.show()


def show_reward_components_demo():
    def shape(text: str) -> str:
        return get_display(arabic_reshaper.reshape(text))

    labels_raw = ["الاتصال", "كفاءة الطاقة", "كفاءة النوم"]
    labels = [shape(t) for t in labels_raw]

    case_a = [0.9, 0.5, 0.4]
    case_b = [0.6, 0.8, 0.7]

    x = np.arange(len(labels))
    width = 0.35

    plt.figure(figsize=(6, 4))
    plt.bar(x - width / 2, case_a, width, label="حالة أ")
    plt.bar(x + width / 2, case_b, width, label="حالة ب")

    plt.xticks(x, labels)
    plt.ylim(0, 1.1)
    plt.ylabel(shape("القيمة (من 0 إلى 1)"))
    plt.title(shape("مقارنة مكوّنات العائد في حالتين"))
    plt.legend([shape("حالة أ"), shape("حالة ب")])
    plt.tight_layout()
    plt.show()


# ==========================================
# 2. واجهة المعلومات (Information Window)
# تشرح المصطلحات العلمية والتقنية للمستخدم
# ==========================================
def create_info_window():
    root = tk.Tk()
    root.title("معلومات عن نموذج التحكم في شبكة الحساسات")

    default_font = ("Tahoma", 10)
    root.option_add("*Font", default_font)

    frame = tk.Frame(root, padx=10, pady=10)
    frame.pack(fill=tk.BOTH, expand=True)

    title_label = tk.Label(frame, text="شرح المتغيرات وإعدادات التدريب", font=("Tahoma", 12, "bold"))
    title_label.pack(anchor="w", pady=(0, 10))

    text_widget = scrolledtext.ScrolledText(frame, wrap=tk.WORD, width=80, height=25)
    text_widget.pack(fill=tk.BOTH, expand=True)

    info_text = """\
ما هو المشروع؟
--------------
- شبكة من حساسات صغيرة تراقب المكان.
- لكل حساس بطارية، والعقل الذكي يقرّر:
  * متى يرسل البيانات.
  * متى ينام لتوفير الطاقة.

ما الذي أستطيع تغييره؟
----------------------
- عدد الحساسات (num_nodes).
- مدى الاتصال بين الحساسات (comm_range).
- عدد مرات التجربة (episodes).

كيف أقرأ النتيجة؟
-----------------
- يظهر رقم اسمه "العائد" (reward) لكل تجربة.
- كلما كان العائد أكبر كان أداء الشبكة أفضل.
- ثم اضغط "تشغيل التقييم":
  * الواجهة ستقوم بإنشاء البيئة والنموذج وفق هذه الإعدادات.
  * إذا كان num_nodes = 10 ويوجد ملف checkpoint مناسب، سيتم استخدام النموذج المدرَّب.
  * إذا كان num_nodes مختلفاً، سيتم استخدام نموذج غير مدرَّب (أوزان عشوائية) وستظهر رسالة تحذير في الطرفية.
  * سيتم عرض منحنى بالعربية يوضح عائد كل حلقة، بالإضافة إلى رسالة بالمتوسط والانحراف المعياري.

8) لمحة مبسّطة عن خوارزمية MAML + Actor-Critic
----------------------------------------------
- "Actor-Critic":
  * "Actor" هو الجزء الذي يقترح الفعل (مثلاً: قوة الإرسال، من ينام ومن يستيقظ).
  * "Critic" هو الجزء الذي يقيم جودة الحالة/الفعل (كم هو جيد هذا القرار على المدى البعيد؟).
  * معًا يشبهان لاعبًا (Actor) ومدربًا (Critic)؛ اللاعب يجرب أفعالًا، والمدرب يعطيه تقييمًا يساعده على التعلم.

- "MAML" (Model-Agnostic Meta-Learning):
  * بدلاً من تدريب نموذج على مهمة واحدة فقط، نحاول تعليمه "كيف يتعلم" بسرعة من مهام متنوعة.
  * في مشروعنا: كل إعداد مختلف للشبكة (مدى اتصال مختلف، توزيع مختلف للعقد) يعتبر "مهمة".
  * MAML تحاول إيجاد مجموعة أوزان مبدئية للنموذج تجعل من السهل عليه التكيف مع مهمة جديدة ببيانات قليلة.

بشكل مبسّط:
- النموذج يجرب قراراته داخل محاكاة الشبكة.
- يحصل على مكافآت حسب جودة الاتصال واستهلاك الطاقة والنوم.
- يستخدم هذه المكافآت ليتعلم تدريجيًا ما هي الاستراتيجيات الأفضل.
- ومع MAML يصبح قادرًا على التكيف بسرعة عندما تتغير شروط الشبكة.

9) ماذا نستفيد من النتائج في الحياة اليومية؟
----------------------------------------
- متوسط العائد (reward) يخبرنا إلى أي درجة قرارات النموذج جيدة في:
  * الحفاظ على اتصال معقول بين الحساسات.
  * تقليل استهلاك الطاقة وإطالة عمر البطارية.
  * استخدام وضع النوم عندما يكون ذلك مفيدًا.

- عندما يكون المتوسط أعلى والانحراف المعياري صغيرًا فهذا يعني:
  * أن الشبكة تعمل بكفاءة أكبر وبشكل أكثر استقرارًا.

أمثلة تطبيقات قريبة من الحياة اليومية:

- المنازل الذكية:
  * حساسات حركة وحرارة وإضاءة لا تحتاج أن تعمل بأقصى طاقة طوال الوقت.
  * النموذج يمكن أن يقرر متى ترسل البيانات ومتى تنام لتوفير الكهرباء والبطاريات.

- المزارع والمدن الذكية:
  * حساسات رطوبة التربة، وجودة الهواء، ومستوى الضوضاء، وغيرها.
  * بدلاً من إرسال البيانات باستمرار، يمكن للشبكة أن ترسل فقط عند الحاجة،
    مع الحفاظ على اتصال كافٍ، مما يقلل من صيانة واستبدال البطاريات.

- كأداة تعليمية:
  * الواجهات في هذا المشروع تسمح لأي شخص أن يغيّر الإعدادات (عدد الحساسات، مدى الاتصال، عدد الحلقات)
    ويرى كيف تتغير النتائج بصريًا.
  * هذا يساعد الطلاب أو المهتمين بالتقنية على فهم فكرة شبكات الاستشعار والتعلّم المعزّز
    وكيف يمكن للذكاء الاصطناعي أن يتعلم من التجربة لتحسين أداء نظام واقعي.

10) أمثلة ورسومات توضيحية بسيطة
-------------------------------
مثال 1: شبكة صغيرة من 3 حساسات
--------------------------------
تخيّل أن لدينا 3 حساسات في خط واحد:

   [حساس 1] ---- [حساس 2] ---- [حساس 3]

إذا كان مدى الاتصال (comm_range) صغيرًا جدًا، قد يصبح الشكل فعليًا هكذا:

   [حساس 1]      [حساس 2]      [حساس 3]

لا توجد أسهم (روابط) بين الحساسات، فينخفض:
- connectivity_score → لأن عدد الروابط الفعلية قليل أو صفر.
- وبالتالي ينخفض العائد (reward)، حتى لو كانت الحساسات محافظة على طاقتها.

إذا زودنا comm_range بشكل معقول، تصبح الروابط متاحة:

   [حساس 1] ---- [حساس 2] ---- [حساس 3]

الآن:
- connectivity_score أعلى.
- إذا حافظنا على استهلاك طاقة معقول (transmit_power ليست عالية جدًا)،
  سيصبح reward أعلى بشكل واضح.

مثال 2: تأثير النوم (sleep_schedule)
------------------------------------
لنفترض أن لدينا 4 حساسات:

   [1] ---- [2] ---- [3] ---- [4]

حالة (أ): كل الحساسات مستيقظة
--------------------------------
sleep_schedule = [0, 0, 0, 0]  (0 = مستيقظ)

- الاتصال ممتاز (كل العقد متصلة).
- لكن استهلاك الطاقة أعلى لأن الجميع يعمل طوال الوقت.
- reward جيد من ناحية الاتصال، لكنه أقل من الناحية الطاقية.

حالة (ب): نعطّل حساسًا وسيطًا خطأً
---------------------------------
sleep_schedule = [0, 1, 0, 0]

أي أن الحساس رقم 2 نائم:

   [1]    X(نائم)    [3] ---- [4]

- الشبكة تنقسم إلى جزئين: 1 لوحده، و3-4 متصلان.
- connectivity_score ينخفض كثيرًا.
- حتى لو وفّرنا طاقة في الحساس 2،
  قد ينخفض reward الكلّي بسبب سوء الاتصال.

حالة (ج): نوم ذكي للأطراف
--------------------------
sleep_schedule = [1, 0, 0, 1]

   X(1 نائم) ---- [2] ---- [3] ---- X(4 نائم)

- الاتصال الأساسي 2–3 ما زال موجودًا ويضمن بعض الترابط.
- الحساسان 1 و4 يوفران طاقة بالنوم.
- في مثل هذه الحالة قد يحصل النموذج على توازن أفضل بين
  الاتصال وكفاءة الطاقة وكفاءة النوم، وبالتالي reward أعلى.

هذه الأمثلة البسيطة يمكن أن تُستخدم في عرض مشروع التخرج
لتوضيح كيف أن تغييرًا صغيرًا في الإعدادات (من ينام؟ ما مدى الاتصال؟)
يمكن أن يؤثر بشكل واضح على النتيجة النهائية (المكافأة والأداء).

"""

    text_widget.insert(tk.END, info_text)
    text_widget.configure(state=tk.DISABLED)

    buttons_frame = tk.Frame(frame, pady=8)
    buttons_frame.pack(fill=tk.X, anchor="e")

    btn_conn = tk.Button(
        buttons_frame,
        text="عرض مثال بصري لمدى الاتصال",
        command=show_connectivity_demo,
    )
    btn_conn.pack(side=tk.LEFT, padx=(0, 5))

    btn_reward = tk.Button(
        buttons_frame,
        text="عرض مثال بصري لمكوّنات العائد",
        command=show_reward_components_demo,
    )
    btn_reward.pack(side=tk.LEFT)

    root.mainloop()


if __name__ == "__main__":
    create_info_window()
